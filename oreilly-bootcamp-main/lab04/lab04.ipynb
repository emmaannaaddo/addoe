{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This code sets up display options, imports, etc.\n",
    "!pip install matplotlib_inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# set up plotting defaults\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats(\"svg\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 3)\n",
    "pio.templates.default = \"simple_white\"\n",
    "\n",
    "# display options for numpy and pandas\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 7)\n",
    "pd.set_option(\"display.max_columns\", 8)\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df(\n",
    "    df, rows=pd.options.display.max_rows, cols=pd.options.display.max_columns\n",
    "):\n",
    "    \"\"\"Displays n rows and cols from df\"\"\"\n",
    "    with pd.option_context(\"display.max_rows\", rows, \"display.max_columns\", cols):\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 4: Case Study on Air Quality\n",
    "\n",
    "**Data Science Bootcamp with Python, Pandas, and Plotly**\n",
    "\n",
    "Mar 14, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Cleaning a US Sensor's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(csv):\n",
    "    return f'https://github.com/DS-100/textbook/raw/master/content/datasets/purpleair_study/{csv}'\n",
    "\n",
    "data('aqs_06-067-0010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqs = pd.read_csv(data('aqs_06-067-0010.csv'))\n",
    "aqs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df(aqs.iloc[0].to_frame(), rows=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data dictionary:\n",
    "\n",
    "https://aqs.epa.gov/aqsweb/airdata/FileFormats.html#_hourly_data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What should we check about the data quality?\n",
    "\n",
    "https://learningds.org/ch/09/wrangling_checks.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the Granularity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_date = (aqs.query('date_local == \"2018-12-31\"')\n",
    " [['date_local', 'pollutant_standard', 'event_type', 'arithmetic_mean']]\n",
    ")\n",
    "display_df(one_date, rows=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can simply take the first PM2.5 measurement for each date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data cleaning step gives us the desired granularity of `aqs`:\n",
    "every row in `aqs` represents a single date, with an average PM2.5\n",
    "measurement for that date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Unneeded Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan to match the PM2.5 measurements in the `aqs` dataframe with\n",
    "the PurpleAir PM2.5 measurements for each date.\n",
    "To simplify the data, we'll subset out the date and PM2.5 columns and rename the\n",
    "PM2.5 column so that it's easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Validity of `date_local`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the `date_local` column.\n",
    "We can already see that there are gaps in dates where there are no\n",
    "PM2.5 readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The table is sorted by `date_local`, so we see that there are missing dates\n",
    "# between 2018-05-20 and 2018-05-23, for example.\n",
    "aqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python strings are recorded as the `object` type in pandas\n",
    "aqs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqs['date_local'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the `date_local` contains timestamps, we can calculate how\n",
    "many dates are missing. We'll find the number of days between the earliest and\n",
    "latest date---this corresponds to the maximum number of measurements we could\n",
    "have recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = aqs['date_local'].max() - aqs['date_local'].min()\n",
    "date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting timestamps give Timedelta objects, which have a few useful\n",
    "# properties like:\n",
    "date_range.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We have {len(aqs)} / {date_range.days} measurements, '\n",
    "      f'or {len(aqs) / date_range.days:.0%} of the dates possible.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Validity of `pm25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(aqs, x='date_local', y='pm25');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Part 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Cleaning a PurpleAir Sensor's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_raw = pd.read_csv(data('purpleair_AMTS/AMTS_TESTING%20(outside)%20(38.568404%20-121.493163)%20Primary%20Real%20Time%2005_20_2018%2012_29_2019.csv'))\n",
    "pa_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df(pa_raw.iloc[0].to_frame().reset_index(), rows=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns that\n",
    "contain PM2.5 data: `PM2.5_CF1_ug/m3` and `PM2.5_ATM_ug/m3`.\n",
    "We'll keep `PM2.5_CF1_ug/m3` since the original researchers found that feature to be\n",
    "more effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_and_rename_A(df):\n",
    "    df = df[['created_at', 'PM2.5_CF1_ug/m3', 'Temperature_F', 'Humidity_%']]\n",
    "    df.columns = ['timestamp', 'PM25cf1', 'TempF',\n",
    "                  'RH'] # RH stands for Relative Humidity\n",
    "    return df\n",
    "\n",
    "pa = (pa_raw\n",
    "      .pipe(subset_and_rename_A))\n",
    "pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the Granularity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to adjust for timezone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pvlib-python.readthedocs.io/en/stable/timetimezones.html\n",
    "# The US/Pacific timezone corresponds to the timezone in California, and will\n",
    "# automatically adjust for Daylight Saving Time.\n",
    "pa.tz_convert('US/Pacific')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'D' argument tells resample to aggregate timestamps into individual dates\n",
    "(pa.resample('D')\n",
    " .size() # We can call aggregation methods just like we would with `groupby()`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_day = (pa\n",
    " .resample('D')\n",
    " .size()\n",
    " .rename('# measurements')\n",
    " .reset_index()\n",
    ")\n",
    "per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(per_day, x='timestamp', y='# measurements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PurpleAir says that its sensors take a recording every 2 minutes. What's weird about this plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is the Sampling Rate Inconsistent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing a string into .loc will filter timestamps\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa.loc['2019-01-01 00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_day = (pa\n",
    " .resample('D')\n",
    " .size()\n",
    " .rename('# measurements')\n",
    " .reset_index()\n",
    ")\n",
    "per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(per_day, x='timestamp', y='# measurements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You Try: What do we do About Missing Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Exploring the Sensor Pair's Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What aspects of this data can we explore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'data/cleaned_purpleair_aqs/Full24hrdataset.csv'\n",
    "usecols = ['Date', 'ID', 'region', 'PM25FM', 'PM25cf1', 'TempC', 'RH', 'Dewpoint']\n",
    "\n",
    "full_df = (pd.read_csv(data('cleaned_purpleair_aqs/Full24hrdataset.csv'),\n",
    "                       usecols=usecols, parse_dates=['Date'])\n",
    "           .dropna())\n",
    "full_df.columns = ['date', 'id', 'region', 'pm25aqs', 'pm25pa', 'temp', 'rh', 'dew']\n",
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column  | Description                                                                                                                      |\n",
    "|---------|----------------------------------------------------------------------------------------------------------------------------------|\n",
    "| date    | Date of the observation                                                                                                          |\n",
    "| id      | A unique label for a site, formatted as the US state abbreviation with a number. (We performed data cleaning for site ID `CA1`.) |\n",
    "| region  | The name of the region, which corresponds to a group of sites. (The `CA1` site is located in the `West` region.)                 |\n",
    "| pm25aqs | The PM2.5 measurement from the AQS sensor.                                                                                       |\n",
    "| pm25pa  | The PM2.5 measurement from the PurpleAir sensor.                                                                                 |\n",
    "| temp    | Temperature, in Celcius.                                                                                                         |\n",
    "| rh      | Relative humidity, ranging from 0 to 100%.                                                                                       |\n",
    "| dew     | The dew point. (Higher dew point means more moisture in the air.)                                                     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (full_df\n",
    " .query('id == \"CA1\"')\n",
    " .melt(['date'], ['pm25aqs', 'pm25pa'], var_name='sensor', value_name='pm25')\n",
    " .sort_values('date')\n",
    ")\n",
    "px.line(df, x='date', y='pm25', color='sensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(full_df, x='pm25aqs', y='pm25pa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_50 = full_df[full_df['pm25aqs'] < 50]\n",
    "px.scatter(under_50, x='pm25aqs', y='pm25pa',\n",
    "           trendline='lowess',\n",
    "           trendline_color_override=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[['pm25aqs', 'pm25pa']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Modeling the Difference between US and PurpleAir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about the code below, I'll explain as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = len(full_df)\n",
    "test_n = 1000\n",
    "\n",
    "# Shuffle the row labels\n",
    "shuffled = np.random.choice(n, size=n, replace=False)\n",
    "\n",
    "# Split the data\n",
    "test  = full_df.iloc[shuffled[:test_n]]\n",
    "train = full_df.iloc[shuffled[test_n:]]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions):\n",
    "    return np.sqrt(np.mean((test['pm25aqs'] - predictions)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def model_results(models):\n",
    "    results = [\n",
    "        [model.__doc__, rmse(model(train)(test))]\n",
    "        for model in models\n",
    "    ]\n",
    "    return (pd.DataFrame(results, columns=['model', 'rmse'])\n",
    "            .set_index('model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-variable model (simple linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def model_1(train):\n",
    "    '''f(x) = θ₀ + θ₁PA'''\n",
    "    # Fit calibration model using sklearn\n",
    "    X, y = train[['pm25aqs']], train['pm25pa']\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    m, b = model.coef_[0], model.intercept_\n",
    "    \n",
    "    # Invert model\n",
    "    theta_1 = 1 / m\n",
    "    theta_0 = - b / m\n",
    "    \n",
    "    def predict(data):\n",
    "        return theta_0 + theta_1 * data['pm25pa']\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results([model_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under this model, $ \\hat \\theta_1 = 0.52 $ and $ \\hat \\theta_0 = 1.54 $, so our\n",
    "fitted model predicts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{PM}_{2.5} = 1.54 + 0.52 \\text{PA}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with both PurpleAir and Relative Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2(train):\n",
    "    '''f(x) = θ₀ + θ₁PA + θ₂RH'''\n",
    "    # Fit calibration model using sklearn\n",
    "    X, y = train[['pm25aqs', 'rh']], train['pm25pa']\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    [m1, m2], b = model.coef_, model.intercept_\n",
    "    \n",
    "    # Invert to find parameters\n",
    "    theta_0 = - b / m1\n",
    "    theta_1 = 1 / m1\n",
    "    theta_2 = - m2 / m1\n",
    "    \n",
    "    def predict(data):\n",
    "        return theta_0 + theta_1 * data['pm25pa'] + theta_2 * data['rh']\n",
    "        return (data['pm25pa'] - data['rh'] * m2 - b) / m1\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results([model_1, model_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the model, we have:\n",
    "$ \\hat \\theta_0 = 5.77 $, $ \\hat \\theta_1 = 0.524 $, and\n",
    "$ \\hat \\theta_2 = -0.0860 $\n",
    "so our fitted model predicts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{PM}_{2.5} = 5.77 + 0.524 \\cdot \\text{PA} - 0.086 \\cdot \\text{RH}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
